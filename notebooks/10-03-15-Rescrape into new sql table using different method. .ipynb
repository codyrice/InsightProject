{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make some new SQL dbs and scrape into them. \n",
    "\n",
    "Scrape the data into a new database for additional feature generation.\n",
    "\n",
    "1. Load some modules. \n",
    "2. Load the data and subselect for various parameters.  \n",
    "3. Connect to the database. \n",
    "3. Write the tables. \n",
    "4. Start scraping!\n",
    "\n",
    "### Load some modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "from os.path import join\n",
    "from pandas import DataFrame,read_csv\n",
    "import numpy as np\n",
    "from os import getcwd,listdir\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.externals import joblib\n",
    "from pandas import DataFrame\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# my own scripts\n",
    "#append the path for my own funtions and import them \n",
    "import sys\n",
    "sys.path.append('/home/ubuntu/InsightProject')\n",
    "from scraper import * \n",
    "from data_functions import *\n",
    "from plotters import *\n",
    "from stats import *\n",
    "\n",
    "# multiprocessing\n",
    "from multiprocessing.pool import ThreadPool as Pool\n",
    "from validators.url import url as validate_url\n",
    "\n",
    "# sqlaclhemy\n",
    "import sqlalchemy as sa\n",
    "from sqlalchemy import Column, Table, MetaData,create_engine\n",
    "from sqlalchemy.dialects.mysql import *\n",
    "from sqlalchemy.sql.expression import insert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data and subselect for various parameters. \n",
    "As part of this process, need to clean the data once again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = '/home/ubuntu/data'\n",
    "hdf = 'GoGuardianClassified_Unique-9-19-2015.hdf'\n",
    "data = pd.read_hdf(join(path, hdf), 'goguardian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>catIDs</th>\n",
       "      <th>catNames</th>\n",
       "      <th>parentIDs</th>\n",
       "      <th>parentNames</th>\n",
       "      <th>number_categories</th>\n",
       "      <th>number_parents</th>\n",
       "      <th>visited</th>\n",
       "      <th>saved</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0--ass-cinema-newsp.da.ru</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[Pornography]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>9205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0--fightingshaving.da.ru</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[Pornography]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>9205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0--foodwarez.da.ru</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[Pornography]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>9205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>0--gratis.dk</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[Pornography]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>0-0-0-1blowjob.da.ru</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[Pornography]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>9205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                        url catIDs       catNames parentIDs parentNames  \\\n",
       "0   3  0--ass-cinema-newsp.da.ru    [2]  [Pornography]     [0.0]       [nan]   \n",
       "1   5   0--fightingshaving.da.ru    [2]  [Pornography]     [0.0]       [nan]   \n",
       "2   6         0--foodwarez.da.ru    [2]  [Pornography]     [0.0]       [nan]   \n",
       "3   7               0--gratis.dk    [2]  [Pornography]     [0.0]       [nan]   \n",
       "4  12       0-0-0-1blowjob.da.ru    [2]  [Pornography]     [0.0]       [nan]   \n",
       "\n",
       "   number_categories  number_parents visited  saved  size  \n",
       "0                  1               1    True   True  9205  \n",
       "1                  1               1    True   True  9205  \n",
       "2                  1               1    True   True  9205  \n",
       "3                  1               1    True  False     0  \n",
       "4                  1               1    True   True  9205  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.query('number_categories ==1')\n",
    "data2 = data.loc[:,['url', 'catNames', 'parentNames'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## convert the catNames and parentNames to a single item \n",
    "data2.catNames = data2.catNames.apply(lambda x: x[0])\n",
    "data2.parentNames = data2.parentNames.apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>catNames</th>\n",
       "      <th>parentNames</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0--ass-cinema-newsp.da.ru</td>\n",
       "      <td>Pornography</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         url     catNames parentNames\n",
       "0  0--ass-cinema-newsp.da.ru  Pornography         NaN"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# change the parentNames to reflect the catNames if NaN\n",
    "categories = data2.copy().iloc[:, [1,2]]\n",
    "\n",
    "categories.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## create a mapping (dict) that maps the catNames to the parent Names.\n",
    "cat_map = {}\n",
    "\n",
    "# note to self that the nans are floats.. \n",
    "for i in xrange(len(categories)):\n",
    "    if isinstance(categories.iloc[i,1], float):\n",
    "        cat_map[categories.iloc[i,0]] = categories.iloc[i,0]\n",
    "    else: \n",
    "        cat_map[categories.iloc[i,0]] = categories.iloc[i,1]     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#use this to map to data\n",
    "data2.parentNames = data2.catNames.map(cat_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# rename the columns\n",
    "data2.columns = ['url', 'Secondary Category', 'Primary Category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## and the filenames\n",
    "data2['filenames'] = data2.url.apply(lambda x: rename_url(x,'.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>Secondary Category</th>\n",
       "      <th>Primary Category</th>\n",
       "      <th>filenames</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0--ass-cinema-newsp.da.ru</td>\n",
       "      <td>Pornography</td>\n",
       "      <td>Pornography</td>\n",
       "      <td>0--ass-cinema-newsp_da_ru.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         url Secondary Category Primary Category  \\\n",
       "0  0--ass-cinema-newsp.da.ru        Pornography      Pornography   \n",
       "\n",
       "                       filenames  \n",
       "0  0--ass-cinema-newsp_da_ru.txt  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda/lib/python2.7/site-packages/pandas/io/pytables.py:2577: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['url', 'Secondary Category', 'Primary Category', 'filenames']]\n",
      "\n",
      "  warnings.warn(ws, PerformanceWarning)\n"
     ]
    }
   ],
   "source": [
    "#save\n",
    "data2.to_hdf(join(path, 'urls_subset-10-03-2015.hdf'),'goguardian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# query to find out which one have been download. \n",
    "html_path = '/home/ubuntu/data/html'\n",
    "download = listdir(html_path)\n",
    "data3 =data2.query('filenames in @download')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Connect to the database. \n",
    "\n",
    "1. connect to the data base and check connection. \n",
    "2. check to see query works. \n",
    "2. create a metadata data object and bind it. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eng = create_engine('mysql://root:what@localhost/url',pool_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('information_schema',), ('mysql',), ('performance_schema',), ('url',)]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng.execute('show databases').fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meta = MetaData()\n",
    "meta.bind = eng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the tables\n",
    "Create a table for the classifed with tags, and a new table for the ones that have not been classified. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classified_tags = Table('classified_tags',meta,\n",
    "                        Column('ID', INTEGER, primary_key=True, autoincrement=True),\n",
    "                        Column('url', VARCHAR(60)),\n",
    "                        Column('filename', VARCHAR(60)),\n",
    "                        Column('primary_category', VARCHAR(60)),\n",
    "                        Column('secondary_category', VARCHAR(60)),\n",
    "                        Column('paragraphs', INTEGER),\n",
    "                        Column('titles', INTEGER),\n",
    "                        Column('links', INTEGER),\n",
    "                        Column('images', INTEGER),\n",
    "                        Column('metas', INTEGER),\n",
    "                        Column('headers', INTEGER),\n",
    "                        Column('word_count', INTEGER),\n",
    "                        Column('text',MEDIUMTEXT)\n",
    "                       )\n",
    "\n",
    "student_tags = Table('student_tags',meta,\n",
    "                        Column('ID', INTEGER, primary_key=True, autoincrement=True),\n",
    "                        Column('url', VARCHAR(60)),\n",
    "                        Column('filename', VARCHAR(60)),\n",
    "                        Column('paragraphs', INTEGER),\n",
    "                        Column('titles', INTEGER),\n",
    "                        Column('links', INTEGER),\n",
    "                        Column('images', INTEGER),\n",
    "                        Column('metas', INTEGER),\n",
    "                        Column('headers', INTEGER),\n",
    "                        Column('word_count', INTEGER),\n",
    "                        Column('text',MEDIUMTEXT)\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## create the tables\n",
    "meta.create_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('information_schema',), ('mysql',), ('performance_schema',), ('url',)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng.execute('show databases').fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start scraping!\n",
    "1. Write function for classified\n",
    "2. execute for classified. \n",
    "3. write function for student_tags\n",
    "4. execute.\n",
    "\n",
    "\n",
    "#### Write function for classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reset the index of data3\n",
    "data3.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def scrape_classified(index):\n",
    "    ## given a row insert into the table \n",
    "    # index is the index. \n",
    "    \n",
    "    #get the row information \n",
    "    row = data3.loc[index]\n",
    "    \n",
    "  \n",
    "    # get the file information  \n",
    "    html_path = '/home/ubuntu/data/html'\n",
    "    filename = join(html_path,row.filenames)\n",
    "    \n",
    "    # scrape the text \n",
    "    text, counts, word_count=scrape_text_and_count_tags(filename)\n",
    "    \n",
    "    # parse out the tag counts\n",
    "    paragraphs,titles, links, images, metas, headers = counts\n",
    "    \n",
    "    #insert into the data base. \n",
    "    eng.dispose()\n",
    "    with eng.connect() as conn:\n",
    "        # insert the data into the database. \n",
    "        ins = classified_tags.insert().values(\n",
    "            url = row.url,\n",
    "            filename = row.filenames,\n",
    "            primary_category = row['Primary Category'],\n",
    "            secondary_category = row['Secondary Category'],\n",
    "            paragraphs = paragraphs,\n",
    "            titles = titles,\n",
    "            links =links,\n",
    "            images =images,\n",
    "            metas = metas,\n",
    "            headers = headers,\n",
    "            word_count = word_count,\n",
    "            text = text\n",
    "                       )\n",
    "        conn.execute(ins)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#try the first one\n",
    "scrape_classified(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scrape baby scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Now use a pool\n",
    "rows = range(1, len(data3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is code for doing the multiproccessing. \n",
    "```python\n",
    "pool = Pool(32)\n",
    "pool.map(scrape_classified, rows)\n",
    "pool.close()```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comments\n",
    "\n",
    "I had a problem with inserting some of the entries because some of them were NaN rather than a string. I need to drop the nan. I do this below and then rescrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sql = pd.read_sql('select * from classified_tags', con = eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1109"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_scraped = data3.query('url not in @sql.url')\n",
    "len(not_scraped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1100"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop the nans\n",
    "not_scraped = not_scraped.dropna()\n",
    "len(not_scraped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rows = not_scraped.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is code for doing the multiproccessing. \n",
    "```python\n",
    "pool = Pool(32)\n",
    "pool.map(scrape_classified, rows)\n",
    "pool.close()```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the entries were double inserted.. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set up code for scrapping the student_tags\n",
    "\n",
    "1. first get a list of the students htmls. \n",
    "2. rewrite the code. \n",
    "3. execute. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "student_path = '/home/ubuntu/data/student_html'\n",
    "student_files = DataFrame({'filenames':listdir(student_path)})\n",
    "student_files['url']= student_files.filenames.apply(lambda x: x.replace('.txt', '').replace('_','.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filenames</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mrpshumanities_weebly_com.txt</td>\n",
       "      <td>mrpshumanities.weebly.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>www_apl_tv.txt</td>\n",
       "      <td>www.apl.tv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>darthassassin_deviantart_com.txt</td>\n",
       "      <td>darthassassin.deviantart.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>esheninger_blogspot_com.txt</td>\n",
       "      <td>esheninger.blogspot.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>www_yamahamotorsports_com.txt</td>\n",
       "      <td>www.yamahamotorsports.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          filenames                           url\n",
       "0     mrpshumanities_weebly_com.txt     mrpshumanities.weebly.com\n",
       "1                    www_apl_tv.txt                    www.apl.tv\n",
       "2  darthassassin_deviantart_com.txt  darthassassin.deviantart.com\n",
       "3       esheninger_blogspot_com.txt       esheninger.blogspot.com\n",
       "4     www_yamahamotorsports_com.txt     www.yamahamotorsports.com"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_files.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scrape_students(index):\n",
    "    ## given a row insert into the table \n",
    "    # index is the index. \n",
    "    \n",
    "    #get the row information \n",
    "    row = student_files.loc[index]\n",
    "    \n",
    "  \n",
    "    # get the file information  \n",
    "    student_path = '/home/ubuntu/data/student_html'\n",
    "    filename = join(student_path,row.filenames)\n",
    "    \n",
    "    # scrape the text \n",
    "    text, counts, word_count=scrape_text_and_count_tags(filename)\n",
    "    \n",
    "    # parse out the tag counts\n",
    "    paragraphs,titles, links, images, metas, headers = counts\n",
    "    \n",
    "    #insert into the data base. \n",
    "    eng.dispose()\n",
    "    with eng.connect() as conn:\n",
    "        # insert the data into the database. \n",
    "        ins = student_tags.insert().values(\n",
    "            url = row.url,\n",
    "            filename = row.filenames,\n",
    "            paragraphs = paragraphs,\n",
    "            titles = titles,\n",
    "            links =links,\n",
    "            images =images,\n",
    "            metas = metas,\n",
    "            headers = headers,\n",
    "            word_count = word_count,\n",
    "            text = text\n",
    "                       )\n",
    "        conn.execute(ins)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Excecute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rows = student_files.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the code that I excecuted to scrape the student htmls and place in the database. \n",
    "Note I did not actually scrape all of them.. \n",
    "\n",
    "``` python\n",
    "pool = Pool(32)\n",
    "pool.map(scrape_students, rows)\n",
    "pool.close()```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remarks\n",
    "\n",
    "Done!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
